<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://arathod02.github.io/docs/blog</id>
    <title>Ashish Rathod Blog</title>
    <updated>2025-12-11T12:26:27.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://arathod02.github.io/docs/blog"/>
    <subtitle>Ashish Rathod Blog</subtitle>
    <icon>https://arathod02.github.io/docs/img/favicon.jpg</icon>
    <entry>
        <title type="html"><![CDATA[A Deep Dive into Database Storage Engines and Soft Deletion Strategies.]]></title>
        <id>https://arathod02.github.io/docs/blog/avoid-hard-deletes</id>
        <link href="https://arathod02.github.io/docs/blog/avoid-hard-deletes"/>
        <updated>2025-12-11T12:26:27.000Z</updated>
        <summary type="html"><![CDATA[A Deep Dive into Database Storage Engines and Soft Deletion Strategies.]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>In the discipline of database architecture, the mechanism of deletion is frequently underestimated. While the creation and retrieval of data receive significant attention regarding optimization and structure, the removal of data—specifically the "Hard Delete"—is often treated as a trivial housekeeping operation. However, an exhaustive analysis of storage engine internals reveals that hard deletion is one of the most resource-intensive and structurally disruptive operations in a relational database management system (RDBMS).</p>
<p>This report provides a comprehensive technical analysis of the storage engines underpinning major databases, specifically MySQL's InnoDB and PostgreSQL's Heap architecture. It articulates the high costs associated with physical record removal, including B+ Tree rebalancing, locking contention, input/output (I/O) thrashing, and vacuum-induced bloat. Consequently, this document advocates for a "Soft Delete by Design" methodology, treating deletion as a logical state transition rather than a physical storage event. It concludes with a robust lifecycle management strategy that couples logical soft deletion with asynchronous, batched hard deletion to maintain long-term storage hygiene without compromising system stability.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-storage-engine-internals">1. Storage Engine Internals<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#1-storage-engine-internals" class="hash-link" aria-label="Direct link to 1. Storage Engine Internals" title="Direct link to 1. Storage Engine Internals" translate="no">​</a></h2>
<p>To comprehend the catastrophic potential of a hard delete, one must first possess a nuanced understanding of how data resides on the disk. The abstraction of a "table" composed of "rows" and "columns" is a logical convenience; the physical reality is a complex arrangement of binary pages, pointers, and trees.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="11-mysql-innodb-the-index-organized-table"><strong>1.1 MySQL InnoDB: The Index-Organized Table</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#11-mysql-innodb-the-index-organized-table" class="hash-link" aria-label="Direct link to 11-mysql-innodb-the-index-organized-table" title="Direct link to 11-mysql-innodb-the-index-organized-table" translate="no">​</a></h3>
<p>In the MySQL ecosystem, the default storage engine is InnoDB. Its defining characteristic is that it does not merely use an index to find data; the table <em>is</em> the index. This architecture is known as a Clustered Index, implemented via a B+ Tree data structure.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="111-the-b-tree-hierarchythe-lifecycle-strategy"><strong>1.1.1 The B+ Tree Hierarchy</strong>The Lifecycle Strategy<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#111-the-b-tree-hierarchythe-lifecycle-strategy" class="hash-link" aria-label="Direct link to 111-the-b-tree-hierarchythe-lifecycle-strategy" title="Direct link to 111-the-b-tree-hierarchythe-lifecycle-strategy" translate="no">​</a></h4>
<p>The B+ Tree is a self-balancing tree structure designed to maintain sorted data and allow searches, sequential access, insertions, and deletions in logarithmic time. It is distinct from a binary tree in its high fan-out; a single node can have hundreds of children, allowing the tree to remain incredibly shallow (usually 3 to 4 levels deep) even for tables containing billions of rows.</p>
<ul>
<li class=""><strong>The Root Page:</strong> The entry point of the tree. It resides at a fixed location and contains pointers to internal nodes.</li>
<li class=""><strong>Internal Nodes (Non-Leaf):</strong> These nodes act as the navigational roadmap. They contain only the Primary Key values and pointers to child pages. Because they do not store the full row data, they are lightweight. A single 16KB page can store hundreds of keys, maximizing the "fan-out" capability and ensuring that traversing the tree requires minimal disk I/O.</li>
<li class=""><strong>Leaf Nodes (The Data):</strong> This is where the physical reality of the Clustered Index becomes apparent. The leaf nodes contain the actual row data—every column of every record.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="112-primary-key-ordering-in-leaf-nodes"><strong>1.1.2 Primary Key Ordering in Leaf Nodes</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#112-primary-key-ordering-in-leaf-nodes" class="hash-link" aria-label="Direct link to 112-primary-key-ordering-in-leaf-nodes" title="Direct link to 112-primary-key-ordering-in-leaf-nodes" translate="no">​</a></h4>
<p>A critical architectural feature of InnoDB is that the leaf nodes are strictly ordered by the Primary Key. This is not a suggestion; it is a physical enforcement. If a table has a Primary Key of ID, the row with ID=1 is physically stored adjacent to ID=2 within the 16KB page.</p>
<p>Furthermore, these leaf nodes are strictly linked in a doubly linked list. Each leaf page contains a pointer to the previous page and the next page. This structure enables the database to perform extremely fast range scans (e.g., SELECT * FROM orders WHERE id BETWEEN 100 AND 200) by traversing the linked list rather than returning to the root node.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="113-page-filling-and-fragmentation"><strong>1.1.3 Page Filling and Fragmentation</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#113-page-filling-and-fragmentation" class="hash-link" aria-label="Direct link to 113-page-filling-and-fragmentation" title="Direct link to 113-page-filling-and-fragmentation" translate="no">​</a></h4>
<p>InnoDB manages storage in units called Pages, typically 16KB in size. When records are inserted sequentially (e.g., using an auto-incrementing integer), InnoDB fills these pages efficiently, leaving only a small fraction (typically 1/16th) free for future modifications. This results in a "Fill Factor" of nearly 100%, ensuring optimal disk usage and cache efficiency.</p>
<p>However, when data is modified or deleted, this order is disturbed. A hard delete creates a physical "hole" in the page. If enough holes are created, the page density drops, leading to fragmentation—a state where the database engine is caching and reading pages that are largely empty air.</p>
<p><strong>Table 1: B+ Tree Node Characteristics</strong></p>
<table><thead><tr><th style="text-align:left">Node Type</th><th style="text-align:left">Content</th><th style="text-align:left">Purpose</th><th style="text-align:left">Density</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Internal Node</strong></td><td style="text-align:left">Primary Keys + Child Pointers</td><td style="text-align:left">Navigation</td><td style="text-align:left">High (Keys only)</td></tr><tr><td style="text-align:left"><strong>Leaf Node</strong></td><td style="text-align:left">Full Row Data</td><td style="text-align:left">Storage</td><td style="text-align:left">Variable (Depends on Row Size)</td></tr><tr><td style="text-align:left"><strong>Leaf Linkage</strong></td><td style="text-align:left">Double Pointers (Prev/Next)</td><td style="text-align:left">Range Scans</td><td style="text-align:left">N/A</td></tr></tbody></table>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="12-postgresql-the-heap-and-tuple-architecture"><strong>1.2 PostgreSQL: The Heap and Tuple Architecture</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#12-postgresql-the-heap-and-tuple-architecture" class="hash-link" aria-label="Direct link to 12-postgresql-the-heap-and-tuple-architecture" title="Direct link to 12-postgresql-the-heap-and-tuple-architecture" translate="no">​</a></h3>
<p>PostgreSQL employs a fundamentally different storage paradigm known as the Heap. Unlike InnoDB, where the table is the index, PostgreSQL separates the table storage (the Heap) from the index storage.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="121-heap-pages-and-item-pointers"><strong>1.2.1 Heap Pages and Item Pointers</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#121-heap-pages-and-item-pointers" class="hash-link" aria-label="Direct link to 121-heap-pages-and-item-pointers" title="Direct link to 121-heap-pages-and-item-pointers" translate="no">​</a></h4>
<p>In PostgreSQL, data is stored in a file known as the "Heap." This file is divided into fixed-length blocks, typically 8KB. Within these blocks, records (referred to as "tuples") are stored in an unordered fashion. A tuple is inserted into the first page that has sufficient free space, regardless of its Primary Key value.</p>
<p>This lack of inherent order necessitates a mechanism to locate data. PostgreSQL uses the Tuple Identifier (TID), often referred to as ctid. The ctid is a coordinate pair: (Block Number, Offset Number). For example, (42, 7) means the 7th item on the 42nd page.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="122-the-array-of-line-pointers"><strong>1.2.2 The Array of Line Pointers</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#122-the-array-of-line-pointers" class="hash-link" aria-label="Direct link to 122-the-array-of-line-pointers" title="Direct link to 122-the-array-of-line-pointers" translate="no">​</a></h4>
<p>To manage the internal organization of an 8KB page, PostgreSQL uses an array of "Line Pointers" (ItemIds) at the beginning of the page header.</p>
<ul>
<li class=""><strong>Indirection:</strong> The ctid actually points to a Line Pointer, not the tuple itself. The Line Pointer then points to the byte offset where the tuple begins within the page.</li>
<li class=""><strong>Why Indirection Matters:</strong> This allows the database to defragment the page internally (move tuples around to close gaps) without changing the ctid or updating external indexes. As long as the Line Pointer at index 7 remains, the tuple can be anywhere in the page.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="123-ordered-indexes-vs-unordered-heap"><strong>1.2.3 Ordered Indexes vs. Unordered Heap</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#123-ordered-indexes-vs-unordered-heap" class="hash-link" aria-label="Direct link to 123-ordered-indexes-vs-unordered-heap" title="Direct link to 123-ordered-indexes-vs-unordered-heap" translate="no">​</a></h4>
<p>It is a common misconception that PostgreSQL tables are ordered by Primary Key. They are not. The Heap is unordered.8 However, the <strong>Primary Key Index</strong> is a B-Tree structure that <em>is</em> strictly ordered. This index stores the Primary Key value and the corresponding ctid of the heap tuple. When a query requests a row by ID, the engine searches the ordered B-Tree Index, finds the ctid, and then retrieves the unordered tuple from the Heap.</p>
<p><strong>Table 2: Comparison of Storage Architectures</strong></p>
<table><thead><tr><th style="text-align:left">Feature</th><th style="text-align:left">MySQL InnoDB (B+ Tree)</th><th style="text-align:left">PostgreSQL (Heap)</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Organization</strong></td><td style="text-align:left">Clustered (Data is in the Index)</td><td style="text-align:left">Heap (Data is separate from Index)</td></tr><tr><td style="text-align:left"><strong>Ordering</strong></td><td style="text-align:left">Physically ordered by Primary Key</td><td style="text-align:left">Unordered (Insert order / Random)</td></tr><tr><td style="text-align:left"><strong>Row ID</strong></td><td style="text-align:left">Primary Key</td><td style="text-align:left">CTID (Block + Offset)</td></tr><tr><td style="text-align:left"><strong>Secondary Index</strong></td><td style="text-align:left">Points to Primary Key Value</td><td style="text-align:left">Points to CTID</td></tr><tr><td style="text-align:left"><strong>Page Size</strong></td><td style="text-align:left">16KB (Default)</td><td style="text-align:left">8KB (Default)</td></tr></tbody></table>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-the-pain-caused-by-hard-deletion">2. The pain caused by Hard Deletion<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#2-the-pain-caused-by-hard-deletion" class="hash-link" aria-label="Direct link to 2. The pain caused by Hard Deletion" title="Direct link to 2. The pain caused by Hard Deletion" translate="no">​</a></h2>
<p>With the storage context established, we can analyze the mechanics of the DELETE command. Far from a simple erasure, a hard delete triggers a complex sequence of internal operations that can destabilize the database.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="21-mysql-innodb-the-rebalancing-storm"><strong>2.1 MySQL InnoDB: The Rebalancing Storm</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#21-mysql-innodb-the-rebalancing-storm" class="hash-link" aria-label="Direct link to 21-mysql-innodb-the-rebalancing-storm" title="Direct link to 21-mysql-innodb-the-rebalancing-storm" translate="no">​</a></h3>
<p>In a B+ Tree, structural integrity is paramount. The tree must remain balanced to ensure predictable performance. Deleting a row threatens this balance.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="211-the-search-and-destroy-mission"><strong>2.1.1 The Search and Destroy Mission</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#211-the-search-and-destroy-mission" class="hash-link" aria-label="Direct link to 211-the-search-and-destroy-mission" title="Direct link to 211-the-search-and-destroy-mission" translate="no">​</a></h4>
<p>When a DELETE is issued, InnoDB must first traverse the tree to locate the leaf node containing the record. Once found, the record is not immediately wiped; it is "delete-marked." This is a logical flag in the record header indicating the space is technically free but occupied by a "ghost".</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="212-the-merge-threshold"><strong>2.1.2 The Merge Threshold</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#212-the-merge-threshold" class="hash-link" aria-label="Direct link to 212-the-merge-threshold" title="Direct link to 212-the-merge-threshold" translate="no">​</a></h4>
<p>The true cost arises when deletions accumulate. Each page has a MERGE_THRESHOLD, typically defaulting to 50%.</p>
<ol>
<li class=""><strong>Underflow:</strong> If a deletion causes the page's data volume to drop below this threshold, InnoDB determines that the page is inefficient.</li>
<li class=""><strong>Locking:</strong> The engine places locks on the page and its neighbors (sibling nodes).</li>
<li class=""><strong>Merge Operation:</strong> It attempts to merge the remaining records into a sibling page (left or right).</li>
<li class=""><strong>Cascading Reparenting:</strong> If a page is emptied and removed, the pointer in the <em>parent</em> node must be deleted. If this deletion causes the <em>parent</em> node to drop below its own threshold, the merge operation propagates upward. This "rebalancing storm" can ripple up to the root, causing massive I/O and locking overhead.</li>
</ol>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="213-secondary-index-maintenance"><strong>2.1.3 Secondary Index Maintenance</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#213-secondary-index-maintenance" class="hash-link" aria-label="Direct link to 213-secondary-index-maintenance" title="Direct link to 213-secondary-index-maintenance" translate="no">​</a></h4>
<p>Every secondary index in InnoDB stores the Primary Key as its pointer. If you delete a user with ID=100, Email=<a href="mailto:bob@test.com" target="_blank" rel="noopener noreferrer" class="">bob@test.com</a>, and Status=Active, InnoDB must:</p>
<ol>
<li class="">Delete 100 from the Clustered Index (B+ Tree).</li>
<li class="">Delete <a href="mailto:bob@test.com" target="_blank" rel="noopener noreferrer" class="">bob@test.com</a> from the Email Index (B+ Tree).</li>
<li class="">Delete Active from the Status Index (B+ Tree).<br>
<!-- -->Each of these requires random I/O operations. While the Change Buffer helps mitigate this for non-unique indexes by caching changes, unique indexes require immediate, synchronous disk operations to enforce constraints, amplifying the I/O cost significantly.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="22-postgresql"><strong>2.2 PostgreSQL</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#22-postgresql" class="hash-link" aria-label="Direct link to 22-postgresql" title="Direct link to 22-postgresql" translate="no">​</a></h3>
<p>PostgreSQL handles deletion via Multi-Version Concurrency Control (MVCC). It does not remove data immediately; it versions it.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="221-the-invisible-update"><strong>2.2.1 The Invisible Update</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#221-the-invisible-update" class="hash-link" aria-label="Direct link to 221-the-invisible-update" title="Direct link to 221-the-invisible-update" translate="no">​</a></h4>
<p>In PostgreSQL, an UPDATE is effectively a DELETE followed by an INSERT. A DELETE is simply an UPDATE that puts nothing back.</p>
<ul>
<li class=""><strong>xmin and xmax:</strong> Every tuple has an xmin (the transaction ID that created it) and an xmax (the transaction ID that deleted it).</li>
<li class=""><strong>Marking as Dead:</strong> When DELETE is run, Postgres finds the tuple and sets its xmax to the current transaction ID. The data remains physically on the disk.</li>
<li class=""><strong>Visibility Rules:</strong> Future transactions check the xmax. If xmax is set and committed, the tuple is invisible. To the storage engine, the page looks exactly the same as before, but the tuple is logically dead.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="222-the-vacuum-necessity"><strong>2.2.2 The Vacuum Necessity</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#222-the-vacuum-necessity" class="hash-link" aria-label="Direct link to 222-the-vacuum-necessity" title="Direct link to 222-the-vacuum-necessity" translate="no">​</a></h4>
<p>Since DELETE does not free space, the table size does not decrease. It creates "Dead Tuples." If these are not cleaned up, the table becomes "bloated"—a mixture of live data and digital corpses.</p>
<ul>
<li class=""><strong>Autovacuum:</strong> The autovacuum daemon runs in the background. It scans tables, looking for dead tuples that are older than any active transaction.</li>
<li class=""><strong>Freeing Space:</strong> It marks the line pointers as "unused," allowing new inserts to overwrite the dead space. However, this process consumes CPU and I/O bandwidth and can block schema changes.</li>
</ul>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-the-performance-impact-of-hard-deletion">3. The Performance Impact of Hard Deletion<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#3-the-performance-impact-of-hard-deletion" class="hash-link" aria-label="Direct link to 3. The Performance Impact of Hard Deletion" title="Direct link to 3. The Performance Impact of Hard Deletion" translate="no">​</a></h2>
<p>The internal mechanics described above manifest as tangible performance degradation in production environments. The impact of hard deletes is rarely linear; it is exponential relative to the volume of data and concurrency of the system.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="31-the-locking-bottleneck"><strong>3.1 The Locking Bottleneck</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#31-the-locking-bottleneck" class="hash-link" aria-label="Direct link to 31-the-locking-bottleneck" title="Direct link to 31-the-locking-bottleneck" translate="no">​</a></h3>
<p>Hard deletes are blocking operations.</p>
<ul>
<li class=""><strong>Gap Locks (MySQL):</strong> To preserve transaction isolation (specifically to prevent "Phantom Reads"), InnoDB places "Gap Locks" on the space <em>between</em> records. If you delete ID=10, InnoDB might lock the gap from ID=5 to ID=15. Any other transaction trying to insert ID=12 will be blocked until the delete commits. In high-concurrency systems, this leads to lock contention and "Lock Wait Timeout Exceeded" errors.</li>
<li class=""><strong>Exclusive Locks:</strong> Both engines take exclusive locks on the specific rows being deleted. If a reporting query is reading those rows, the delete will block (or vice versa), causing system stutter.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="32-io-thrashing-and-buffer-pool-pollution"><strong>3.2 I/O Thrashing and Buffer Pool Pollution</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#32-io-thrashing-and-buffer-pool-pollution" class="hash-link" aria-label="Direct link to 32-io-thrashing-and-buffer-pool-pollution" title="Direct link to 32-io-thrashing-and-buffer-pool-pollution" translate="no">​</a></h3>
<p>Database performance relies heavily on caching "hot" pages in RAM (Buffer Pool).</p>
<ul>
<li class=""><strong>Random Access:</strong> Hard deletes are often random (e.g., deleting users who cancelled today). This forces the database to load widely scattered pages from the disk into memory just to mark a single bit.</li>
<li class=""><strong>Dirty Pages:</strong> Modifying a page marks it as "dirty." Dirty pages must be flushed back to disk. A massive delete operation creates a flood of dirty pages, saturating the I/O subsystem and slowing down critical read operations.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="33-index-bloat-and-degradation"><strong>3.3 Index Bloat and Degradation</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#33-index-bloat-and-degradation" class="hash-link" aria-label="Direct link to 33-index-bloat-and-degradation" title="Direct link to 33-index-bloat-and-degradation" translate="no">​</a></h3>
<ul>
<li class=""><strong>Postgres Index Bloat:</strong> In PostgreSQL, indexes contain pointers to heap tuples. When a tuple is updated or deleted, the index entry remains until Vacuum runs. If a table is heavily churned (high delete/update rate), the indexes can grow larger than the table itself. Larger indexes equate to slower searches, as they are less likely to fit in RAM.</li>
<li class=""><strong>MySQL Fragmentation:</strong> As described in Section 2.1.2, B+ Tree pages that are 50-60% full are inefficient. This fragmentation means that to read 1GB of actual data, the engine might need to read 2GB of disk pages, effectively halving the I/O throughput.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-the-architectural-solution-soft-deletion">4. The Architectural Solution: Soft Deletion<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#4-the-architectural-solution-soft-deletion" class="hash-link" aria-label="Direct link to 4. The Architectural Solution: Soft Deletion" title="Direct link to 4. The Architectural Solution: Soft Deletion" translate="no">​</a></h2>
<p>The "Soft Delete" pattern solves the physical storage problems by decoupling the <strong>business intent</strong> of deletion from the <strong>database mechanism</strong> of deletion. Instead of instructing the storage engine to perform a destructive structural change, the application performs a non-structural state change.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="41-implementation-patterns"><strong>4.1 Implementation Patterns</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#41-implementation-patterns" class="hash-link" aria-label="Direct link to 41-implementation-patterns" title="Direct link to 41-implementation-patterns" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="411-the-boolean-flag"><strong>4.1.1 The Boolean Flag</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#411-the-boolean-flag" class="hash-link" aria-label="Direct link to 411-the-boolean-flag" title="Direct link to 411-the-boolean-flag" translate="no">​</a></h4>
<p>The simplest implementation is a boolean column.</p>
<ul>
<li class=""><strong>Schema:</strong> is_deleted BOOLEAN DEFAULT FALSE</li>
<li class=""><strong>Logic:</strong> UPDATE table SET is_deleted = TRUE WHERE id = 1</li>
<li class=""><strong>Critique:</strong> While lightweight, this pattern lacks context. It tells you <em>that</em> a record was deleted, but not <em>when</em>.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="412-the-timestamp-recommended"><strong>4.1.2 The Timestamp (Recommended)</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#412-the-timestamp-recommended" class="hash-link" aria-label="Direct link to 412-the-timestamp-recommended" title="Direct link to 412-the-timestamp-recommended" translate="no">​</a></h4>
<p>The industry standard pattern involves a nullable timestamp.</p>
<ul>
<li class=""><strong>Schema:</strong> deleted_at TIMESTAMP NULL</li>
<li class=""><strong>Logic:</strong> UPDATE table SET deleted_at = NOW() WHERE id = 1</li>
<li class=""><strong>Query:</strong> SELECT * FROM table WHERE deleted_at IS NULL</li>
<li class=""><strong>Benefit:</strong> This acts as a boolean flag (Null/NotNull) while simultaneously providing an audit trail of the deletion event.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="413-the-status-enum"><strong>4.1.3 The Status Enum</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#413-the-status-enum" class="hash-link" aria-label="Direct link to 413-the-status-enum" title="Direct link to 413-the-status-enum" translate="no">​</a></h4>
<p>For complex state machines, deletion is just one of many states.</p>
<ul>
<li class=""><strong>Schema:</strong> status VARCHAR(20) CHECK (status IN ('active', 'pending', 'archived', 'deleted'))</li>
<li class=""><strong>Benefit:</strong> Useful when "deletion" is part of a workflow, such as a "Recycle Bin" that transitions to "Permanently Deleted."</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="42-why-soft-deletes-resolve-storage-issues"><strong>4.2 Why Soft Deletes Resolve Storage Issues</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#42-why-soft-deletes-resolve-storage-issues" class="hash-link" aria-label="Direct link to 42-why-soft-deletes-resolve-storage-issues" title="Direct link to 42-why-soft-deletes-resolve-storage-issues" translate="no">​</a></h3>
<ol>
<li class=""><strong>Zero Rebalancing:</strong> Updating a deleted_at timestamp is an in-place update. In MySQL, since the Primary Key is not changing, the row does not move. The B+ Tree structure remains perfectly balanced. No page merges occur.</li>
<li class=""><strong>Preserved Sequentiality:</strong> The data remains physically adjacent. Sequential read performance is preserved.</li>
<li class=""><strong>Reduced Locking:</strong> An update to a non-indexed column (like deleted_at) generally requires only a row lock, avoiding the aggressive Gap Locks associated with structural removal.</li>
</ol>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-business-use-cases-for-soft-deletion">5. Business Use Cases for Soft Deletion<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#5-business-use-cases-for-soft-deletion" class="hash-link" aria-label="Direct link to 5. Business Use Cases for Soft Deletion" title="Direct link to 5. Business Use Cases for Soft Deletion" translate="no">​</a></h2>
<p>Beyond performance optimization, Soft Deletion enables critical business capabilities that Hard Deletion inherently destroys.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="51-recoverability-the-undo-button"><strong>5.1 Recoverability: The "Undo" Button</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#51-recoverability-the-undo-button" class="hash-link" aria-label="Direct link to 51-recoverability-the-undo-button" title="Direct link to 51-recoverability-the-undo-button" translate="no">​</a></h3>
<p>Human error is an inevitability in software systems.</p>
<ul>
<li class=""><strong>Unintended Deletes:</strong> Users frequently delete content accidentally on mobile devices. Soft deletes allow for an immediate "Undo" feature without complex backup restoration.</li>
<li class=""><strong>Production Safety:</strong> Engineering history is replete with stories of developers accidentally running DELETE without a WHERE clause. With soft deletes, this catastrophe is reversible via a simple SQL UPDATE statement (UPDATE table SET deleted_at = NULL). With hard deletes, this becomes a disaster recovery scenario requiring Point-in-Time Recovery (PITR), potentially costing hours of downtime and data loss.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="52-audit-and-compliance"><strong>5.2 Audit and Compliance</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#52-audit-and-compliance" class="hash-link" aria-label="Direct link to 52-audit-and-compliance" title="Direct link to 52-audit-and-compliance" translate="no">​</a></h3>
<p>In regulated industries, data deletion is often a legal construct rather than a physical one.</p>
<ul>
<li class=""><strong>Traceability:</strong> A deleted_at column, often paired with deleted_by_user_id, provides an immutable audit trail. Organizations can answer inquiries such as "Who cancelled this order?" or "When was this account terminated?".</li>
<li class=""><strong>Legal Obligations:</strong> Depending upon the business, some regulations might mandate data retention for 7-10 years. A user's request to "delete my account" must be balanced against the legal requirement to "retain transaction history." Soft deletion satisfies the user's visibility requirement while satisfying the regulator's retention requirement.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="53-referential-integrity-and-cascading"><strong>5.3 Referential Integrity and Cascading</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#53-referential-integrity-and-cascading" class="hash-link" aria-label="Direct link to 53-referential-integrity-and-cascading" title="Direct link to 53-referential-integrity-and-cascading" translate="no">​</a></h3>
<p>Relational databases enforce integrity via Foreign Keys. You cannot delete a Parent if it has Children.</p>
<ul>
<li class=""><strong>Hard Delete Complexity:</strong> To hard delete a User, you must first delete their Orders, Invoices, Logs, and Comments. This triggers a massive "Cascading Delete" transaction that can touch dozens of tables and lock millions of rows.</li>
<li class=""><strong>Soft Delete Simplicity:</strong> You simply mark the User as deleted. The child records remain untouched (and referentially valid). The application layer is responsible for filtering out "Orders belonging to deleted Users" during display. This avoids the massive transactional overhead of cascading deletes.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-disadvantages-and-engineering-trade-offs">6. Disadvantages and Engineering Trade-offs<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#6-disadvantages-and-engineering-trade-offs" class="hash-link" aria-label="Direct link to 6. Disadvantages and Engineering Trade-offs" title="Direct link to 6. Disadvantages and Engineering Trade-offs" translate="no">​</a></h2>
<p>Soft deletion is an architectural compromise. It solves storage and recovery issues but introduces application-layer complexity.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="61-the-forgotten-where-clause"><strong>6.1 The "Forgotten WHERE Clause"</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#61-the-forgotten-where-clause" class="hash-link" aria-label="Direct link to 61-the-forgotten-where-clause" title="Direct link to 61-the-forgotten-where-clause" translate="no">​</a></h3>
<p>The most pervasive risk is query correctness.</p>
<ul>
<li class=""><strong>The Leak:</strong> Every query in the application must now include AND deleted_at IS NULL. If a developer forgets this clause in a "Total Revenue" report, the report will incorrectly include refunded (deleted) orders.</li>
<li class=""><strong>Mitigation:</strong>
<ul>
<li class=""><strong>ORM Scopes:</strong> Use framework features (e.g., Hibernate @Where, Eloquent SoftDeletes) to automatically inject this clause.</li>
<li class=""><strong>Views:</strong> Create a database view active_users that filters the data, and restrict application access to the view rather than the raw table.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="62-index-bloat"><strong>6.2 Index Bloat</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#62-index-bloat" class="hash-link" aria-label="Direct link to 62-index-bloat" title="Direct link to 62-index-bloat" translate="no">​</a></h3>
<p>Soft-deleted rows are still physically present. If a table contains 90% deleted data (e.g., a queue table), the indexes will be 90% "junk." This reduces the effectiveness of the RAM cache, as valuable memory is wasted storing pointers to deleted data.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="7-the-lifecycle-strategy-batch-hard-deletion">7. The Lifecycle Strategy: Batch Hard Deletion<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#7-the-lifecycle-strategy-batch-hard-deletion" class="hash-link" aria-label="Direct link to 7. The Lifecycle Strategy: Batch Hard Deletion" title="Direct link to 7. The Lifecycle Strategy: Batch Hard Deletion" translate="no">​</a></h2>
<p>We have established that Hard Deletes are destructive, but Soft Deletes cause unlimited growth (bloat). The optimal architecture is a hybrid lifecycle: <strong>Soft Delete for Operations, Batch Hard Delete for Maintenance.</strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="71-the-nightly-batch-deletion-job"><strong>7.1 The "Nightly" Batch Deletion Job</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#71-the-nightly-batch-deletion-job" class="hash-link" aria-label="Direct link to 71-the-nightly-batch-deletion-job" title="Direct link to 71-the-nightly-batch-deletion-job" translate="no">​</a></h3>
<p>The goal is to decouple the high-frequency user action (clicking delete) from the high-cost database operation (physical removal).</p>
<ol>
<li class=""><strong>User Action:</strong> Soft Delete. Instant, safe, recoverable.</li>
<li class=""><strong>Retention Policy:</strong> "We keep deleted data for 30 days."</li>
<li class=""><strong>Background Process:</strong> A nightly job runs during off-peak hours (e.g., 3:00 AM) to physically purge records older than 30 days.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="72-why-batching-is-superior"><strong>7.2 Why Batching is Superior</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#72-why-batching-is-superior" class="hash-link" aria-label="Direct link to 72-why-batching-is-superior" title="Direct link to 72-why-batching-is-superior" translate="no">​</a></h3>
<ul>
<li class=""><strong>Amortized I/O:</strong> Loading a page to delete 100 records is 100x more efficient than loading that page 100 separate times to delete 1 record at a time.</li>
<li class=""><strong>Sequential Access:</strong> Batch jobs can process deletions in Primary Key order, ensuring the disk head moves linearly.</li>
<li class=""><strong>Reduced Locking:</strong> The batch job can lock a small range, perform the delete, and release the lock, minimizing impact on active users.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="73-implementation-chunked-deletion"><strong>7.3 Implementation: Chunked Deletion</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#73-implementation-chunked-deletion" class="hash-link" aria-label="Direct link to 73-implementation-chunked-deletion" title="Direct link to 73-implementation-chunked-deletion" translate="no">​</a></h3>
<p>Running DELETE FROM logs WHERE created_at &lt; '2023-01-01' is dangerous. It will attempt to lock millions of rows, potentially crashing the database. The correct approach is <strong>Chunking</strong>.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="algorithm"><strong>Algorithm</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#algorithm" class="hash-link" aria-label="Direct link to algorithm" title="Direct link to algorithm" translate="no">​</a></h4>
<ol>
<li class="">Identify the target rows.</li>
<li class="">Delete in small batches (e.g., 1000 rows).</li>
<li class="">Sleep/Throttle between batches to allow replication to catch up and CPU to cool down.</li>
</ol>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="mysql-example-stored-procedure"><strong>MySQL Example (Stored Procedure)</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#mysql-example-stored-procedure" class="hash-link" aria-label="Direct link to mysql-example-stored-procedure" title="Direct link to mysql-example-stored-procedure" translate="no">​</a></h4>
<p>MySQL allows LIMIT in DELETE statements, enabling simple chunking.</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">PROCEDURE</span><span class="token plain"> PurgeOldData</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">BEGIN</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">REPEAT</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">-- Delete 1000 rows, ordered by ID to maintain B-Tree locality  </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">DELETE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> users   </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> deleted\_at \</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">DATE</span><span class="token plain">\_SUB</span><span class="token punctuation" style="color:#393A34">(</span><span class="token function" style="color:#d73a49">NOW</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">INTERVAL</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">30</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">DAY</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">   </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">ORDER</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">BY</span><span class="token plain"> id   </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">LIMIT</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">-- Sleep to prevent lock contention  </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">DO</span><span class="token plain"> SLEEP</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0.5</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">UNTIL </span><span class="token keyword" style="color:#00009f">ROW</span><span class="token plain">\_COUNT</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">END</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">REPEAT</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">END</span><span class="token plain">  </span><br></span></code></pre></div></div>
<p>Note: The ORDER BY id clause is critical. It ensures the deletion walks the B+ Tree leaves sequentially, preventing random I/O thrashing.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="postgresql-example-cte"><strong>PostgreSQL Example (CTE)</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#postgresql-example-cte" class="hash-link" aria-label="Direct link to postgresql-example-cte" title="Direct link to postgresql-example-cte" translate="no">​</a></h4>
<p>PostgreSQL requires a Common Table Expression (CTE) to achieve similar chunking with lock skipping.</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">WITH</span><span class="token plain"> rows_to_delete </span><span class="token keyword" style="color:#00009f">AS</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"> ctid  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> users  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> deleted_at </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">NOW</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">INTERVAL</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">'30 days'</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">LIMIT</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1000</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">FOR</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">UPDATE</span><span class="token plain"> SKIP LOCKED </span><span class="token comment" style="color:#999988;font-style:italic">-- Critical: Skip rows currently in use  </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">DELETE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"> users u  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">USING</span><span class="token plain"> rows_to_delete d  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">WHERE</span><span class="token plain"> u</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ctid </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> d</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ctid</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre></div></div>
<p>Note: FOR UPDATE SKIP LOCKED allows the maintenance job to run concurrently with user activity without blocking.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="74-partition-pruning"><strong>7.4 Partition Pruning</strong><a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#74-partition-pruning" class="hash-link" aria-label="Direct link to 74-partition-pruning" title="Direct link to 74-partition-pruning" translate="no">​</a></h3>
<p>For massive datasets (e.g., Audit Logs, Event Streams), even batch deletion is too slow. The architectural solution is <strong>Table Partitioning</strong>.</p>
<ul>
<li class=""><strong>Strategy:</strong> Partition the table by date (e.g., audit_2023_01, audit_2023_02).</li>
<li class=""><strong>Deletion:</strong> When January's data expires, you do not run DELETE. You run DROP TABLE audit_2023_01.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="8-conclusion">8. Conclusion<a href="https://arathod02.github.io/docs/blog/avoid-hard-deletes#8-conclusion" class="hash-link" aria-label="Direct link to 8. Conclusion" title="Direct link to 8. Conclusion" translate="no">​</a></h2>
<p>The decision to adopt Soft Deletes is not merely a preference for data retention; it is a fundamental alignment with the physics of database storage engines.</p>
<ul>
<li class=""><strong>Hard Deletes</strong> operate <em>against</em> the grain of the storage engine, forcing expensive rebalancing, causing fragmentation, and introducing dangerous locking contention in OLTP systems.</li>
<li class=""><strong>Soft Deletes</strong> operate <em>with</em> the grain, converting destructive structural changes into efficient state updates. They provide the safety net required for modern applications, enabling undo capabilities, audit trails, and simplified synchronization.</li>
</ul>
<p>By implementing Soft Deletes by design, combined with a disciplined Batch Hard Delete lifecycle, architects can build systems that remain performant, recoverable, and stable under scale.</p>]]></content>
        <author>
            <name>Ashish Rathod</name>
            <uri>https://www.linkedin.com/in/ashish-rathod02/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Thundering Herd - Understanding and Solving the Cache Stampede]]></title>
        <id>https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd</id>
        <link href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd"/>
        <updated>2025-12-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In the world of high-scale distributed systems, caching is our best friend. It’s the primary defense layer that protects our fragile databases from the onslaught of user traffic, ensuring low latency and high throughput.]]></summary>
        <content type="html"><![CDATA[<p>In the world of high-scale distributed systems, caching is our best friend. It’s the primary defense layer that protects our fragile databases from the onslaught of user traffic, ensuring low latency and high throughput.</p>
<p>But what happens when that defense layer momentarily fails exactly when you need it most?</p>
<p>Welcome to the <strong>Cache Stampede</strong> problem—also known as the "Thundering Herd." It's a scenario where the very mechanism designed to speed up your system ends up bringing it to its knees.</p>
<p>Let's dive into what it is, why it happens, and the practical techniques used by major systems (like CDNs) to solve it.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-typical-architecture"><strong>The Typical Architecture</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-typical-architecture" class="hash-link" aria-label="Direct link to the-typical-architecture" title="Direct link to the-typical-architecture" translate="no">​</a></h2>
<p>Before things go wrong, let's look at how things go right.</p>
<p>Consider a standard three-tier web architecture. We have API servers fronted by a load balancer. Sitting between these API servers and the "source of truth" (the Database) is a caching layer (like Redis or Memcached).</p>
<p>The goal of the cache is simple: serve data fast and reduce load on the database.</p>
<p>Here is a high-level view of this architecture:</p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-happy-path-flow"><strong>The "Happy Path" Flow</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-happy-path-flow" class="hash-link" aria-label="Direct link to the-happy-path-flow" title="Direct link to the-happy-path-flow" translate="no">​</a></h3>
<p>Under normal operation, the flow for retrieving data is a standard "Read-Through" cache pattern:</p>
<ol>
<li class="">The API Server receives a request for a specific key.</li>
<li class="">It first checks the cache.</li>
<li class=""><strong>Cache Hit:</strong> If the data is there, return it immediately. (Fast!)</li>
<li class=""><strong>Cache Miss:</strong> If the data is <em>not</em> there:<!-- -->
<ul>
<li class="">Query the Database (Slow).</li>
<li class="">Populate the cache with the result for future requests.</li>
<li class="">Return the result to the client.</li>
</ul>
</li>
</ol>
<p>Here is what this typically looks like in simple Java pseudo-code:</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">public class SimpleDataService {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    private Cache cache;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    private Database db;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public String getData(String key) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 1. Try fetching from cache  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        String cachedValue = cache.get(key);  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (cachedValue != null) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return cachedValue;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 2. Cache miss - fetch from source of truth  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        String dbValue = db.query(key);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 3. Backfill cache for next time  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Note: Often done with a Time-To-Live (TTL) to ensure freshness  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cache.put(key, dbValue, Duration.ofMinutes(5)); </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return dbValue;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>This works perfectly fine for normal traffic loads. The database only sees an occasional read when cache items expire.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-problem-the-stampede-begins"><strong>The Problem: The Stampede Begins</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-problem-the-stampede-begins" class="hash-link" aria-label="Direct link to the-problem-the-stampede-begins" title="Direct link to the-problem-the-stampede-begins" translate="no">​</a></h2>
<p>Now, imagine a scenario where a piece of content goes viral.</p>
<p>Suddenly, you have thousands of concurrent requests hitting your load balancer for the exact same resource key (e.g., product_details_123).</p>
<p>If the cache entry for product_details_123 has just expired, or perhaps was evicted due to memory pressure, you have a problem.</p>
<p>In that brief window of time—perhaps just a few hundred milliseconds before the first request can refill the cache—<strong>every single concurrent request will result in a Cache Miss.</strong></p>
<p>If 5,000 requests arrive simultaneously for that missing key, all 5,000 requests will bypass the cache and bombard your database at the exact same moment.</p>
<p>Your database, which was happily serving a few dozen requests per second, suddenly receives thousands. CPU spikes, connection pools become exhausted, queries time out, and the database might even crash. This is the Cache Stampede. It defeats the entire purpose of having a cache.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-solution-request-hedging-debouncing"><strong>The Solution: Request Hedging (Debouncing)</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-solution-request-hedging-debouncing" class="hash-link" aria-label="Direct link to the-solution-request-hedging-debouncing" title="Direct link to the-solution-request-hedging-debouncing" translate="no">​</a></h2>
<p>To handle this, we need to ensure that when a "hot" cache key is missing, we don't let the entire herd stampede to the database. We need to designate a leader.</p>
<p>We leverage a technique known as <strong>Request Hedging</strong> or <strong>Debouncing</strong>.</p>
<p>The concept is straightforward: Out of the thousands of concurrent requests for the missing key, we allow <strong>only one</strong> to proceed to the database. All other requests for that same key must <strong>wait</strong> until that first request completes the job and refills the cache. Once the cache is refilled, the waiting requests can read the data from the cache and proceed.</p>
<p>The idea is simple, but as always, the devil is in the implementation details. How do we make requests wait efficiently and cleanly in a highly concurrent environment? Let's look at two approaches in Java.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="approach-1-the-busy-wait-spinlock"><strong>Approach 1: The Busy Wait (Spinlock)</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#approach-1-the-busy-wait-spinlock" class="hash-link" aria-label="Direct link to approach-1-the-busy-wait-spinlock" title="Direct link to approach-1-the-busy-wait-spinlock" translate="no">​</a></h3>
<p>In this technique, if a thread finds a cache miss, it enters a loop where it continuously checks the cache again after sleeping for a tiny duration. It "spins" until data appears.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="pseudo-code-busy-wait"><strong>Pseudo-code (Busy Wait)</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#pseudo-code-busy-wait" class="hash-link" aria-label="Direct link to pseudo-code-busy-wait" title="Direct link to pseudo-code-busy-wait" translate="no">​</a></h4>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">public class BusyWaitDataService {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    private Cache cache;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    private Database db;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public String getData(String key) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        String value = cache.get(key);  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // If cache hit, return immediately  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (value != null) return value;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Determine if I am the "leader" responsible for fetching.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Use an atomic operation like 'setIfAbsent' (NX) in Redis.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // Set a short TTL on this lock to prevent deadlocks if the service crashes.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        boolean acquiredLock = cache.setIfAbsent("lock::" + key, "locked", Duration.ofSeconds(5));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (acquiredLock) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            try {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // I am the leader. Fetch from DB.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                value = db.query(key);  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                cache.put(key, value, Duration.ofMinutes(5));  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            } finally {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // Release lock so others know fetching is done  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                cache.delete("lock::" + key);  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } else {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // I am a follower. Spin and wait.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            while (value == null) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                try {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    // Sleep briefly to avoid hammering CPU  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    Thread.sleep(50);   </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                } catch (InterruptedException e) { Thread.currentThread().interrupt(); }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // Check cache again  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                value = cache.get(key);  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                // Optional: Check if lock still exists, if not, break and retry fetch  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return value;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-downside"><strong>The Downside</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-downside" class="hash-link" aria-label="Direct link to the-downside" title="Direct link to the-downside" translate="no">​</a></h4>
<p>As the name suggests, this approach makes the CPU "busy." Even though the threads are sleeping, the constant context switching and polling consumes precious CPU cycles. In high-load scenarios, this wasted CPU can become substantial. It works, but it's not elegant.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="approach-2-the-waitnotify-mechanism-jvm-locksfutures"><strong>Approach 2: The Wait/Notify Mechanism (JVM Locks/Futures)</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#approach-2-the-waitnotify-mechanism-jvm-locksfutures" class="hash-link" aria-label="Direct link to approach-2-the-waitnotify-mechanism-jvm-locksfutures" title="Direct link to approach-2-the-waitnotify-mechanism-jvm-locksfutures" translate="no">​</a></h3>
<p>A far more efficient approach is to use native concurrency constructs. Instead of polling, threads should block and go to sleep until they are explicitly notified that the data is ready.</p>
<p>In modern Java, a CompletableFuture combined with a ConcurrentHashMap is a robust way to implement this "promise" pattern without getting tangled in low-level monitor locks (synchronized/wait/notify).</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="pseudo-code-waitnotify-with-futures"><strong>Pseudo-code (Wait/Notify with Futures)</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#pseudo-code-waitnotify-with-futures" class="hash-link" aria-label="Direct link to pseudo-code-waitnotify-with-futures" title="Direct link to pseudo-code-waitnotify-with-futures" translate="no">​</a></h4>
<p>We maintain a local map of "pending database operations." If a request comes in and an operation is already pending for that key, we hook into that existing operation's future result.</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import java.util.concurrent.*;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public class BlogService {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   // "use threadsafe implementation here"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   // sem_map: Tracks which keys are currently being fetched</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   private final ConcurrentHashMap&lt;String, CountDownLatch&gt; semMap = new ConcurrentHashMap&lt;&gt;();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   // res_map: Temporary storage for followers to grab the result immediately</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   // Note: In a real impl, this might need a TTL (e.g., "1 min" per your note) or explicit cleanup</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   private final ConcurrentHashMap&lt;String, String&gt; resMap = new ConcurrentHashMap&lt;&gt;();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   public String getBlog(String k) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      // 1. Check main cache first</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      String v = cache.get(k);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      if (v != null) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         return v;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      // 2. Check Semaphore Map (Thread-safe check)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      // We attempt to create a "lock" (Latch) for this key.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      CountDownLatch myLatch = new CountDownLatch(1); // Starts "blocked"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      // "s = sem_map.get(k)" equivalent using atomic putIfAbsent</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      // If returns value: someone else is already fetching (we are follower)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      // If returns null: we successfully inserted (we are leader)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      CountDownLatch existingLatch = semMap.putIfAbsent(k, myLatch);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      if (existingLatch != null) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         // --- FOLLOWER PATH ("if s: s.wait()") ---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Wait for the leader to signal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            existingLatch.await();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return resMap.get(k);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         } catch (InterruptedException e) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Thread.currentThread().interrupt();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return null;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      } else {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         // --- LEADER PATH ("else") ---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            v = db.query(k);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // "cache.put(k, v)"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cache.put(k, v);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // "res_map[k] = v" (Temporary map)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            resMap.put(k, v);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return v;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         } finally {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Open the gate for followers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            myLatch.countDown();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            //Cleanup lock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            semMap.remove(k);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            // Optional: You might schedule resMap cleanup here or rely on TTL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-benefit"><strong>The Benefit</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-benefit" class="hash-link" aria-label="Direct link to the-benefit" title="Direct link to the-benefit" translate="no">​</a></h4>
<p>This approach is highly efficient. Waiting threads are parked by the OS and consume virtually no CPU until the leader thread completes the future. It handles concurrency cleanly within a single JVM.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-pragmatic-scope-jvm-vs-distributed-locks"><strong>The Pragmatic Scope: JVM vs. Distributed Locks</strong><a href="https://arathod02.github.io/docs/blog/cache-stampede-thundering-herd#the-pragmatic-scope-jvm-vs-distributed-locks" class="hash-link" aria-label="Direct link to the-pragmatic-scope-jvm-vs-distributed-locks" title="Direct link to the-pragmatic-scope-jvm-vs-distributed-locks" translate="no">​</a></h3>
<p>A sharp observer might notice a slight flaw in Approach 2. The guardrails of approach 2 exist within the memory of a <em>single</em> API server JVM.</p>
<p>If you have a fleet of 20 API servers behind your load balancer, and a stampede occurs, <em>one</em> request on <em>each</em> of the 20 servers will proceed to the database.</p>
<p>Instead of 5,000 database hits, you will have 20 hits.</p>
<p>Is this perfect? No. To reduce it to exactly one global hit, you would need a <strong>Distributed Lock</strong> system (using Redis, Zookeeper, or etcd) to coordinate locking across all 20 servers.</p>
<p>However, distributed locks introduce significant complexity, latency, and a new point of failure.</p>
<p><strong>In practice, the JVM-level solution is often the pragmatic choice.</strong> Reducing 5,000 simultaneous requests down to 20 is usually sufficient to save the database. It's a massive improvement for relatively low implementation complexity.</p>
<p>It's worth noting that large-scale Content Delivery Networks (CDNs) like Cloudflare, Akamai, and Fastly use exactly this hedging technique at their edge locations to protect customer origin servers from getting overwhelmed when content goes viral.</p>]]></content>
        <author>
            <name>Ashish Rathod</name>
            <uri>https://www.linkedin.com/in/ashish-rathod02/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Design an Online/Offline Indicator (Presence Service)]]></title>
        <id>https://arathod02.github.io/docs/blog/offline-online-indicator</id>
        <link href="https://arathod02.github.io/docs/blog/offline-online-indicator"/>
        <updated>2025-12-10T10:55:15.000Z</updated>
        <summary type="html"><![CDATA[Designing a scalable presence system for 1 billion users.]]></summary>
        <content type="html"><![CDATA[<p>Designing a system to indicate if a user is <strong>Online</strong> or <strong>Offline</strong> (and their last seen timestamp) sounds simple on the surface, but becomes a massive engineering challenge when scaling to <strong>1 Billion users</strong>.</p>
<p>In this post, we will breakdown the design of a Presence Service suitable for a massive social network or chat application like WhatsApp or Facebook Messenger.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="problem-statement">Problem Statement<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#problem-statement" class="hash-link" aria-label="Direct link to Problem Statement" title="Direct link to Problem Statement" translate="no">​</a></h2>
<p>We need to build a service that indicates the availability status of a user's connections.</p>
<p><strong>The Functional Requirements:</strong></p>
<ol>
<li class="">Indicate if a friend/connection is currently <strong>Online</strong>.</li>
<li class="">If offline, display the <strong>Last Seen</strong> timestamp.</li>
</ol>
<p><strong>The Scale:</strong></p>
<ul>
<li class=""><strong>Total Users:</strong> ~1 Billion.</li>
<li class=""><strong>Concurrent Online Users:</strong> ~500 Million.</li>
<li class=""><strong>Latency:</strong> The status needs to be near real-time.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="high-level-strategy-push-vs-pull">High-Level Strategy: Push vs. Pull<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#high-level-strategy-push-vs-pull" class="hash-link" aria-label="Direct link to High-Level Strategy: Push vs. Pull" title="Direct link to High-Level Strategy: Push vs. Pull" translate="no">​</a></h2>
<p>How do we keep the server updated about the client's status?</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="option-1-pull-polling">Option 1: Pull (Polling)<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#option-1-pull-polling" class="hash-link" aria-label="Direct link to Option 1: Pull (Polling)" title="Direct link to Option 1: Pull (Polling)" translate="no">​</a></h3>
<p>The server periodically connects to the client to ask, "Are you there?"</p>
<ul>
<li class=""><strong>Verdict:</strong> ❌ <strong>Impossible.</strong></li>
<li class=""><strong>Reasoning:</strong> In a mobile/NAT environment, servers cannot initiate connections to clients easily. Furthermore, polling 1B users is computationally wasteful.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="option-2-push-heartbeat">Option 2: Push (Heartbeat)<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#option-2-push-heartbeat" class="hash-link" aria-label="Direct link to Option 2: Push (Heartbeat)" title="Direct link to Option 2: Push (Heartbeat)" translate="no">​</a></h3>
<p>The client sends a signal to the server periodically saying, "I am alive."</p>
<ul>
<li class=""><strong>Verdict:</strong> ✅ <strong>Selected.</strong></li>
<li class=""><strong>Reasoning:</strong> This is the standard pattern for presence. If the server stops receiving heartbeats (after a timeout threshold), the user is marked offline.</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-protocol-http-vs-websockets">The Protocol: HTTP vs. WebSockets<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#the-protocol-http-vs-websockets" class="hash-link" aria-label="Direct link to The Protocol: HTTP vs. WebSockets" title="Direct link to The Protocol: HTTP vs. WebSockets" translate="no">​</a></h2>
<p>We established a "Push" model, but how should the client push this data?</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-resthttp-based">1. REST/HTTP Based<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#1-resthttp-based" class="hash-link" aria-label="Direct link to 1. REST/HTTP Based" title="Direct link to 1. REST/HTTP Based" translate="no">​</a></h3>
<p>The client sends a <code>POST /health</code> request every <em>N</em> seconds.</p>
<p><strong>Why this fails at scale:</strong></p>
<ul>
<li class=""><strong>Overhead:</strong> HTTP is stateless. Every heartbeat requires a full 3-way TCP handshake (if not using keep-alive efficiently), SSL handshake overhead, and heavy HTTP headers.</li>
<li class=""><strong>Traffic:</strong> With 500M concurrent users sending a heartbeat every 10 seconds, that is <strong>50 Million requests per second</strong>. Most of the data transferred would be HTTP headers, not the actual status payload.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-persistent-websockets">2. Persistent WebSockets<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#2-persistent-websockets" class="hash-link" aria-label="Direct link to 2. Persistent WebSockets" title="Direct link to 2. Persistent WebSockets" translate="no">​</a></h3>
<p>The client opens a long-lived, bi-directional connection with the server.</p>
<p><strong>Why this is the winner:</strong></p>
<ul>
<li class=""><strong>Reduced Overhead:</strong> Once the connection is established, data frames have minimal overhead (just a few bytes). There are no repeated headers or handshakes.</li>
<li class=""><strong>Real-time:</strong> The server knows <em>immediately</em> if a connection is severed (TCP FIN or RST).</li>
<li class=""><strong>Bi-directional:</strong> It allows the server to push status updates of <em>friends</em> back to the user over the same channel.</li>
</ul>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>The "Disconnect" Fallacy</div><div class="admonitionContent_BuS1"><p>A common misconception is that WebSockets natively handle all disconnects via an <code>onDisconnect</code> event.</p><ul>
<li class=""><strong>Clean Disconnect:</strong> If a user clicks "Logout", the client sends a TCP FIN. The server knows immediately.</li>
<li class=""><strong>Dirty Disconnect:</strong> If the user loses internet connectivity or the connection is broken for any reason, <strong>the server receives nothing.</strong></li>
<li class=""><strong>The Fix:</strong> We must implement an <strong>Application-Level Heartbeat</strong>. If the server doesn't receive a "Ping" frame or message within $N$ seconds, it forcibly closes the socket and marks the user offline.</li>
</ul></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Scaling WebSockets</div><div class="admonitionContent_BuS1"><p>Scaling persistent connections is harder than scaling stateless HTTP.</p><ol>
<li class=""><strong>OS Limits:</strong> You must tune the kernel to allow &gt;65k open file descriptors (ephemeral ports) per server.</li>
<li class=""><strong>Load Balancing:</strong> You need a Layer 7 Load Balancer that supports "Sticky Sessions" effectively, though for a pure presence service, state can be externalized.</li>
<li class=""><strong>Memory:</strong> Holding 500M open connections requires massive RAM across your fleet of connection handlers (Gateway Service).</li>
</ol></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="database-design--estimation">Database Design &amp; Estimation<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#database-design--estimation" class="hash-link" aria-label="Direct link to Database Design &amp; Estimation" title="Direct link to Database Design &amp; Estimation" translate="no">​</a></h2>
<p>The compute layer is pretty. All it has to do is upon receiving the request, perform a key value based insert or lookup and simply return back to the client. The complexity lies in the <strong>storage layer</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="query-patterns">Query Patterns<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#query-patterns" class="hash-link" aria-label="Direct link to Query Patterns" title="Direct link to Query Patterns" translate="no">​</a></h3>
<ol>
<li class=""><strong>Write (Heavy):</strong> Update User <em>A</em>'s timestamp (Heartbeat).</li>
<li class=""><strong>Read (Heavy):</strong> Get status for User <em>A</em>'s friends/connections when User <em>A</em> opens the app.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-schema">Data Schema<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#data-schema" class="hash-link" aria-label="Direct link to Data Schema" title="Direct link to Data Schema" translate="no">​</a></h3>
<p>We need a simple Key-Value pair.</p>
<table><thead><tr><th style="text-align:left">Field</th><th style="text-align:left">Type</th><th>Size</th></tr></thead><tbody><tr><td style="text-align:left">UserID</td><td style="text-align:left">Integer</td><td>4 Bytes</td></tr><tr><td style="text-align:left">LastSeen</td><td style="text-align:left">Epoch (Int)</td><td>4 Bytes</td></tr><tr><td style="text-align:left"><strong>Total</strong></td><td style="text-align:left"></td><td><strong>8 Bytes</strong></td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="capacity-planning">Capacity Planning<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#capacity-planning" class="hash-link" aria-label="Direct link to Capacity Planning" title="Direct link to Capacity Planning" translate="no">​</a></h3>
<p>With 1 Billion users, do we need massive storage?</p>
<p>1,000,000,000 users * 8 bytes = 8 GB</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Insight</div><div class="admonitionContent_BuS1"><p>We only need <strong>~8 GB</strong> of storage to hold the state of every user on the planet. This entire dataset can fit into the RAM of a single modern server instance.</p></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="managing-online-state-lifecycle">Managing "Online" State Lifecycle<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#managing-online-state-lifecycle" class="hash-link" aria-label="Direct link to Managing &quot;Online&quot; State Lifecycle" title="Direct link to Managing &quot;Online&quot; State Lifecycle" translate="no">​</a></h2>
<p>How do we decide when to switch a user from Online to Offline? We have three strategies.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-the-cron-job-reaper">1. The Cron Job Reaper<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#1-the-cron-job-reaper" class="hash-link" aria-label="Direct link to 1. The Cron Job Reaper" title="Direct link to 1. The Cron Job Reaper" translate="no">​</a></h3>
<p>A background process scans the database every few minutes and deletes entries older than $N$ minutes.</p>
<ul>
<li class=""><strong>Pros:</strong> Keeps DB clean eventually.</li>
<li class=""><strong>Cons:</strong> <strong>Terrible at scale.</strong> Scanning a table of 500M rows every minute creates massive read pressure and locking issues. The "Offline" status will always be laggy.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-connection-events-explicit-disconnect">2. Connection Events (Explicit Disconnect)<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#2-connection-events-explicit-disconnect" class="hash-link" aria-label="Direct link to 2. Connection Events (Explicit Disconnect)" title="Direct link to 2. Connection Events (Explicit Disconnect)" translate="no">​</a></h3>
<p>Leverage WebSocket callbacks (<code>onConnect</code>, <code>onDisconnect</code>) to update the DB.</p>
<ul>
<li class=""><strong>Pros:</strong> extremely efficient. Writes only happen on state changes.</li>
<li class=""><strong>Cons:</strong> Unreliable. If a user loses network (enters a tunnel) or the app crashes, the <code>onDisconnect</code> event might never fire sent to the server. The user will appear "Online" forever (a Zombie session).</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-database-ttl-time-to-live">3. Database TTL (Time-To-Live)<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#3-database-ttl-time-to-live" class="hash-link" aria-label="Direct link to 3. Database TTL (Time-To-Live)" title="Direct link to 3. Database TTL (Time-To-Live)" translate="no">​</a></h3>
<p>Use the database's native feature to auto-expire keys. The Heartbeat simply resets the TTL.</p>
<ul>
<li class=""><strong>Pros:</strong> Handles "unclean" disconnects gracefully. If the heartbeat stops, the key vanishes automatically. No manual cleanup required.</li>
<li class=""><strong>Cons:</strong> Moderate write load (every heartbeat is a write to reset the TTL).</li>
</ul>
<p><strong>Verdict:</strong> We will use <strong>Option 3 (TTL)</strong> as the primary mechanism, potentially optimized by Option 2 (explicitly deleting the key on a clean logout to avoid the TTL wait).</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="database-selection-redis-vs-dynamodb">Database Selection: Redis vs. DynamoDB<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#database-selection-redis-vs-dynamodb" class="hash-link" aria-label="Direct link to Database Selection: Redis vs. DynamoDB" title="Direct link to Database Selection: Redis vs. DynamoDB" translate="no">​</a></h2>
<p>We need a Key-Value store that handles massive write throughput.</p>
<p><strong>The Math:</strong></p>
<ul>
<li class="">500 Million concurrent users.</li>
<li class="">Heartbeat interval: 30 seconds.</li>
<li class="">Throughput = $500,000,000 / 30 \approx$ <strong>16.6 Million Writes/Second</strong>.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="candidate-1-amazon-dynamodb">Candidate 1: Amazon DynamoDB<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#candidate-1-amazon-dynamodb" class="hash-link" aria-label="Direct link to Candidate 1: Amazon DynamoDB" title="Direct link to Candidate 1: Amazon DynamoDB" translate="no">​</a></h3>
<ul>
<li class=""><strong>Pros:</strong> Serverless, high durability, multi-region replication (Global Tables).</li>
<li class=""><strong>Cons:</strong> <strong>Cost and Hot Partitions.</strong>
<ul>
<li class="">Cost: DynamoDB charges by <strong>Write Capacity Units (WCUs)</strong>.<!-- -->
<ul>
<li class="">16.6 Million writes/sec = <strong>16.6 Million WCUs</strong>.</li>
<li class="">Cost per WCU (Provisioned) $\approx $0.00065$ / hour.</li>
<li class=""><strong>Hourly Cost:</strong> $$10,833$.</li>
<li class=""><strong>Monthly Cost:</strong> <strong>~$7.9 Million / Month</strong>.</li>
</ul>
</li>
<li class="">Hot Partition: In DynamoDB, a single partition is strictly limited to <strong>1,000 WCUs</strong>. If 2,000 users map to the same partition key, requests get throttled.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="candidate-2-redis-the-winner">Candidate 2: Redis (The Winner)<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#candidate-2-redis-the-winner" class="hash-link" aria-label="Direct link to Candidate 2: Redis (The Winner)" title="Direct link to Candidate 2: Redis (The Winner)" translate="no">​</a></h3>
<p>Redis is an in-memory store. We are limited by CPU/Network throughput per node.</p>
<ul>
<li class=""><strong>Pros:</strong>
<ul>
<li class=""><strong>In-Memory Speed:</strong> Sub-millisecond reads/writes.</li>
<li class=""><strong>Native TTL:</strong> Redis handles key expiration natively and efficiently.</li>
<li class=""><strong>Cost Effective:</strong>
<ul>
<li class="">Redis is an in-memory store. We are limited by CPU/Network throughput per node.</li>
<li class="">A single robust Redis node (e.g., AWS <code>r7g.xlarge</code>) can handle <strong>~600,000 writes/sec</strong>. (<strong>Benchmark</strong>: <a href="https://aws.plainenglish.io/aws-elasticache-a-performance-and-cost-analysis-of-redis-7-1-vs-valkey-7-2-bfac4fb5c22a" target="_blank" rel="noopener noreferrer" class="">https://aws.plainenglish.io/aws-elasticache-a-performance-and-cost-analysis-of-redis-7-1-vs-valkey-7-2-bfac4fb5c22a</a>)</li>
<li class="">Nodes required: $16,600,000 / 600,000 \approx$ <strong>28 Shards</strong>.</li>
<li class="">Cost per node $\approx $0.30$ / hour.</li>
<li class=""><strong>Monthly Cost:</strong> $28 * $0.30 * 730 hours = <strong>~$6132 / Month</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class=""><strong>Cons:</strong>
<ul>
<li class=""><strong>Persistence:</strong> If Redis crashes, we lose "Last Seen" data (unless AOF mode is enabled, which slows performance).</li>
</ul>
</li>
<li class=""><strong>Mitigation:</strong> For a Presence system, <em>ephemeral</em> data loss is acceptable. If Redis crashes, users briefly appear offline until their next heartbeat (seconds later).</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Cost Epiphany</div><div class="admonitionContent_BuS1"><p>By choosing Redis over DynamoDB for this high-throughput/ephemeral workload, we save the company roughly <strong>$7.89 Million per month</strong>.</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="final-architecture">Final Architecture<a href="https://arathod02.github.io/docs/blog/offline-online-indicator#final-architecture" class="hash-link" aria-label="Direct link to Final Architecture" title="Direct link to Final Architecture" translate="no">​</a></h2>
]]></content>
        <author>
            <name>Ashish Rathod</name>
            <uri>https://www.linkedin.com/in/ashish-rathod02/</uri>
        </author>
    </entry>
</feed>