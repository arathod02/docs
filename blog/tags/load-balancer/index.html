<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">One post tagged with &quot;load-balancer&quot; | Ashish Rathod</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://arathod02.github.io/docs/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://arathod02.github.io/docs/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://arathod02.github.io/docs/blog/tags/load-balancer"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="One post tagged with &quot;load-balancer&quot; | Ashish Rathod"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/docs/img/favicon.jpg"><link data-rh="true" rel="canonical" href="https://arathod02.github.io/docs/blog/tags/load-balancer"><link data-rh="true" rel="alternate" href="https://arathod02.github.io/docs/blog/tags/load-balancer" hreflang="en"><link data-rh="true" rel="alternate" href="https://arathod02.github.io/docs/blog/tags/load-balancer" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/docs/blog/rss.xml" title="Ashish Rathod RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/docs/blog/atom.xml" title="Ashish Rathod Atom Feed"><link rel="stylesheet" href="/docs/assets/css/styles.aade1aad.css">
<script src="/docs/assets/js/runtime~main.2307e74a.js" defer="defer"></script>
<script src="/docs/assets/js/main.4a3975e2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/docs/img/favicon.jpg"><link rel="preload" as="image" href="https://github.com/arathod02.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/"><div class="navbar__logo"><img src="/docs/img/favicon.jpg" alt="Ashish Rathod Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/img/favicon.jpg" alt="Ashish Rathod Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Ashish Rathod</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/load-balancer-design">Designing L7 Load Balancer</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/concurrent-replace">Avoid &quot;REPLACE INTO&quot;</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/slack-design">Slack Architecture</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/distributed-key-value-store">Distributed Key-Value Store</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/db-pessimistic-optimistic-locking">Deep Dive into Database Pessimistic &amp; Optimistic Locking</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/proxy-server">Database Proxy Servers</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/server-sent-events-explained">Real-Time Communication with Server-Sent Events (SSE)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/application-level-sharding-design">Implementing Shard Aware Application</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/scaling-distributed-systems">Scaling Distributed Systems (Focus on Databases)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/avoid-hard-deletes">The Pains of Hard Delete</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/cache-stampede-thundering-herd">The Thundering Herd - Understanding and Solving the Cache Stampede</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/transformer-architecture">The Transformer Architecture</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docs/blog/offline-online-indicator">Presence Service</a></li></ul></div></nav></aside><main class="col col--7"><header class="margin-bottom--xl"><h1>One post tagged with &quot;load-balancer&quot;</h1><a href="/docs/blog/tags">View All Tags</a></header><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/docs/blog/load-balancer-design">Designing L7 Load Balancer</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2025-12-30T00:00:00.000Z">December 30, 2025</time> · <!-- -->14 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/docs/blog/authors/ashish"><img class="avatar__photo authorImage_XqGP" src="https://github.com/arathod02.png" alt="Ashish Rathod"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/docs/blog/authors/ashish"><span class="authorName_yefp" translate="no">Ashish Rathod</span></a></div><small class="authorTitle_nd0D" title="Ex-Intuit Staff Engineer">Ex-Intuit Staff Engineer</small><div class="authorSocials_rSDt"><a href="https://www.linkedin.com/in/ashish-rathod02/" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" preserveAspectRatio="xMidYMid" viewBox="0 0 256 256" style="--dark:#0a66c2;--light:#ffffffe6" class="authorSocialIcon_XYv3 linkedinSvg_FCgI"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453"></path></svg></a><a href="https://github.com/arathod02" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialIcon_XYv3 githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div class="markdown"><p>In this series, we will evolve the design of a Layer 7 Load Balancer (LB) from scratch. We won&#x27;t just look at <em>how</em> to build it, but <em>why</em> we make specific architectural choices at every fork in the road.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-define-the-requirements">1) Define the Requirements<a href="#1-define-the-requirements" class="hash-link" aria-label="Direct link to 1) Define the Requirements" title="Direct link to 1) Define the Requirements" translate="no">​</a></h2>
<p>Before writing code, we must define the &quot;must-haves&quot; of our system.</p>
<ul>
<li class=""><strong>Load the Balance:</strong> The core responsibility is distributing incoming network traffic across multiple backend servers to ensure no single server becomes a bottleneck. This maximizes throughput and minimizes response time.</li>
<li class=""><strong>Tunable Algorithm:</strong> We cannot rely on a single distribution strategy. Different workloads require different approaches (e.g., Round Robin for uniform services, Weighted Round Robin for heterogenous capacity, or Least Connections for long-lived sessions).</li>
<li class=""><strong>Scaling beyond single Load Balancer:</strong> The LB itself shouldn&#x27;t become the single point of failure (SPOF) or the bottleneck. We must design for horizontal scalability where we can add more LB nodes dynamically as traffic increases.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-need-of-persistence-for-the-lb-configurations">2) Need of Persistence for the LB Configurations<a href="#2-need-of-persistence-for-the-lb-configurations" class="hash-link" aria-label="Direct link to 2) Need of Persistence for the LB Configurations" title="Direct link to 2) Need of Persistence for the LB Configurations" translate="no">​</a></h2>
<p>Why do we need a database for a load balancer? Can&#x27;t we just hardcode the backend IPs in a config file?</p>
<p>In a modern distributed system, the environment is dynamic. Backend servers auto-scale (scale-out/in), health checks fail, and routing rules change. If we hardcode configurations, every change requires a redeployment of the Load Balancer fleet. This is unacceptable.</p>
<p>We need to decouple the <strong>Control Plane</strong> (Configuration Management) from the <strong>Data Plane</strong> (Traffic Forwarding). Administrators should be able to tune parameters (add backends, change algorithms, update health check paths) via a console, and these changes must persist in a reliable store that the LB instances can read from.</p>
<p><strong>Architecture V1:</strong></p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2a-need-of-cache-for-the-lb-configurations">2.a) Need of cache for the LB configurations<a href="#2a-need-of-cache-for-the-lb-configurations" class="hash-link" aria-label="Direct link to 2.a) Need of cache for the LB configurations" title="Direct link to 2.a) Need of cache for the LB configurations" translate="no">​</a></h3>
<p>While the architecture above works functionally, it fails non-functionally. If the Load Balancer hits the Configuration DB for <strong>every single request</strong>, we introduce massive latency.</p>
<ul>
<li class=""><strong>Load Balancer Overheads:</strong> The time spent by the LB processing the request before forwarding it.</li>
<li class=""><strong>The Latency Cost:</strong> If a network round-trip to the DB takes 5ms, we are adding 5ms to <em>every</em> user request. In high-throughput systems (100k+ RPS), this also creates a &quot;Thundering Herd&quot; problem that will crush the database.</li>
</ul>
<p><strong>Constraint:</strong> LB overhead must be extremely minimal (sub-millisecond).</p>
<p>To solve this, we introduce an <strong>In-Memory Cache</strong> within the Load Balancer. The LB reads from its local RAM, which is nanosecond-latency fast.</p>
<p><strong>The Data Model (Key-Value):</strong>
We need a simple Key-Value store structure where the key is the LB Group Name and the value is the configuration blob.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token property" style="color:#36acaa">&quot;lb-group-1&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;backend_servers&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;10.0.0.1:80&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;10.0.0.2:80&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;health_endpoint&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/health&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;health_endpoint_expected_code&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">200</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;health_check_frequency_seconds&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;algorithm&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;WEIGHTED_ROUND_ROBIN&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<p>However, caching introduces a classic distributed system problem: <strong>Cache Staleness</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2b-how-to-keep-the-cache-in-sync-with-the-configurations-db">2.b) How to keep the cache in sync with the Configurations DB<a href="#2b-how-to-keep-the-cache-in-sync-with-the-configurations-db" class="hash-link" aria-label="Direct link to 2.b) How to keep the cache in sync with the Configurations DB" title="Direct link to 2.b) How to keep the cache in sync with the Configurations DB" translate="no">​</a></h3>
<p>If an admin adds a new backend server to the DB, the LB&#x27;s in-memory cache still holds the old list. We need a sync mechanism.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="option-1-the-pull-approach-polling">Option 1: The PULL Approach (Polling)<a href="#option-1-the-pull-approach-polling" class="hash-link" aria-label="Direct link to Option 1: The PULL Approach (Polling)" title="Direct link to Option 1: The PULL Approach (Polling)" translate="no">​</a></h4>
<p>We run a background cron job on the LB every 10 seconds to fetch the latest config from the DB.</p>
<ul>
<li class=""><strong>The Problem:</strong> There is a &quot;Staleness Window&quot; of up to 10 seconds. If a backend server is removed from the DB because it was corrupted, the LB might still send traffic to it for 10 seconds, causing 5xx errors for users.</li>
<li class=""><strong>Verdict:</strong> Acceptable for low-criticality systems, but &quot;bad product experience&quot; for high-availability requirements.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="option-2-the-push-based-approach">Option 2: The PUSH Based Approach<a href="#option-2-the-push-based-approach" class="hash-link" aria-label="Direct link to Option 2: The PUSH Based Approach" title="Direct link to Option 2: The PUSH Based Approach" translate="no">​</a></h4>
<p>In this model, whenever the Configuration DB is updated, it actively &quot;pushes&quot; a notification to all Load Balancers to invalidate or update their cache immediately.</p>
<ul>
<li class=""><strong>The Advantage:</strong> This minimizes the staleness window to mere milliseconds. The system reacts in near real-time.</li>
<li class=""><strong>Verdict:</strong> Preferred for production-grade Load Balancers.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2c-choice-of-configuration-db">2.c) Choice of Configuration DB<a href="#2c-choice-of-configuration-db" class="hash-link" aria-label="Direct link to 2.c) Choice of Configuration DB" title="Direct link to 2.c) Choice of Configuration DB" translate="no">​</a></h3>
<p>We need a technology that offers <strong>Persistence</strong> (durability) + <strong>Key-Value Lookup</strong> + <strong>Push/Watch Capabilities</strong>.</p>
<p>Let&#x27;s evaluate the options:</p>
<ol>
<li class="">
<p><strong>Kafka:</strong></p>
<ul>
<li class=""><em>Analysis:</em> Kafka is an event streaming platform, not a configuration store. It is fundamentally PULL-based (consumers poll for messages). Using it as a source of truth for current state is an anti-pattern (requires log compaction gymnastics).</li>
<li class=""><em>Verdict:</em> <strong>Reject.</strong></li>
</ul>
</li>
<li class="">
<p><strong>DynamoDB + DynamoDB Streams:</strong></p>
<ul>
<li class=""><em>Analysis:</em> Excellent for persistence and HA. However, DynamoDB Streams require a Lambda or consumer to poll the stream and then fan-out updates. It doesn&#x27;t provide a native &quot;direct-to-client&quot; push channel.</li>
<li class=""><em>Verdict:</em> <strong>Reject</strong> (Too much glue code required).</li>
</ul>
</li>
<li class="">
<p><strong>Redis Pub/Sub:</strong></p>
<ul>
<li class=""><em>Analysis:</em> Redis is a fantastic KV store. Pub/Sub allows the &quot;Control Plane&quot; to publish an update to a channel that all LBs subscribe to.</li>
<li class=""><em>The Risk:</em> Redis Pub/Sub operates on &quot;At-Most-Once&quot; delivery. If an LB node restarts or has a network blip during the publish event, it <strong>misses the message forever</strong>. It has no persistence for the channel messages.</li>
<li class=""><em>High Availability:</em> Redis Sentinel can provide HA, but it is historically tricky to configure correctly to avoid split-brain scenarios. Relying on it for the &quot;source of truth&quot; configuration can be risky without a backup polling mechanism.</li>
<li class=""><em>Verdict:</em> <strong>Good</strong>, but requires a &quot;safety net&quot; (occasional polling).</li>
</ul>
</li>
<li class="">
<p><strong>ZooKeeper (The Winner):</strong></p>
<ul>
<li class=""><em>Analysis:</em> ZooKeeper is explicitly designed for distributed coordination and configuration management.</li>
<li class=""><em>ZNodes:</em> It stores data in file-system-like paths (Key-Value style).</li>
<li class=""><em>Watches (The Push Mechanism):</em> Clients can place a &quot;Watch&quot; on a ZNode. When the data changes, ZooKeeper sends a notification to the client. This is a robust Push mechanism.</li>
<li class=""><em>Consistency:</em> It uses the ZAB (ZooKeeper Atomic Broadcast) protocol, guaranteeing strong consistency.</li>
<li class=""><em>High Availability:</em> Running a ZK Ensemble (3 or 5 nodes) tolerates node failures without data loss.</li>
<li class=""><em>Verdict:</em> <strong>Excellent Fit.</strong> It solves Persistence + Push + HA natively.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="final-architecture-for-persistence-layer">Final Architecture for Persistence Layer<a href="#final-architecture-for-persistence-layer" class="hash-link" aria-label="Direct link to Final Architecture for Persistence Layer" title="Direct link to Final Architecture for Persistence Layer" translate="no">​</a></h3>
<p>We will use <strong>ZooKeeper</strong> as our configuration source of truth.</p>
<ol>
<li class=""><strong>Control Plane</strong> writes config to ZooKeeper ZNode (<code>/lb-configs/lb-1</code>).</li>
<li class=""><strong>Load Balancers</strong> keep a &quot;Watch&quot; on that ZNode.</li>
<li class=""><strong>Event:</strong> When config changes, ZK notifies all LBs.</li>
<li class=""><strong>Action:</strong> LBs fetch the new data, update their local In-Memory Cache, and re-set the Watch.</li>
</ol>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-need-of-orchestrator-layer-to-monitor-the-health-of-backend-servers">3) Need of Orchestrator layer to monitor the health of backend servers<a href="#3-need-of-orchestrator-layer-to-monitor-the-health-of-backend-servers" class="hash-link" aria-label="Direct link to 3) Need of Orchestrator layer to monitor the health of backend servers" title="Direct link to 3) Need of Orchestrator layer to monitor the health of backend servers" translate="no">​</a></h2>
<p>A Load Balancer is only as good as the servers it points to. If a backend server crashes, gets overloaded, or becomes unresponsive, the Load Balancer must stop sending traffic to it immediately. Without this &quot;circuit breaking&quot; capability, a single failing server can cause a cascade of errors for the end users (502 Bad Gateway), turning a partial outage into a total system failure. The LB needs an intelligent subsystem to actively verify that its destinations are actually capable of handling work.</p>
<p><strong>Enter the Orchestrator.</strong></p>
<p>The Orchestrator acts as the &quot;Health Monitor&quot; of our system. It operates in a continuous loop:</p>
<ol>
<li class=""><strong>Fetch Configuration:</strong> It continually watches the Configuration DB (ZooKeeper) to know which backend servers are supposed to be active and what their health check parameters are (e.g., endpoint <code>/health</code>, interval <code>10s</code>).</li>
<li class=""><strong>Probe:</strong> It actively sends HTTP requests (or TCP pings) to these endpoints on the backend servers.</li>
<li class=""><strong>Decide &amp; Update:</strong> If a server fails to respond with a <code>200 OK</code> for a configured threshold (e.g., 3 consecutive failures), the Orchestrator marks it as &quot;Unhealthy.&quot; It then updates the Configuration DB (ZooKeeper), effectively removing that server from the active rotation. Since our LBs are watching ZooKeeper, they immediately stop routing traffic to the dead node.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3a-making-the-orchestrator-layer-highly-available">3.a) Making the Orchestrator layer Highly Available<a href="#3a-making-the-orchestrator-layer-highly-available" class="hash-link" aria-label="Direct link to 3.a) Making the Orchestrator layer Highly Available" title="Direct link to 3.a) Making the Orchestrator layer Highly Available" translate="no">​</a></h3>
<p>We cannot rely on a single Orchestrator node. If that single node dies, health checks stop. If health checks stop, the Load Balancers are flying blind—they might route traffic to dead servers (false negatives) or fail to route to recovered servers (false positives).</p>
<p>To solve this, we implement a <strong>Master-Worker Architecture with Leader Election</strong>:</p>
<ul>
<li class=""><strong>Master Node:</strong> Responsible for coordination. It divides the list of backend servers into chunks and assigns them to different Worker nodes to balance the health-checking load.</li>
<li class=""><strong>Worker Nodes:</strong> These are the workhorses. They perform the actual HTTP pings to the backend servers and report status back to the Master or directly to the DB.</li>
<li class=""><strong>Self-Healing &amp; Leader Election:</strong> We leverage <strong>ZooKeeper&#x27;s Ephemeral Nodes</strong> for this. All Orchestrator nodes attempt to create a lock file (ZNode) in ZooKeeper.<!-- -->
<ul>
<li class="">The node that succeeds becomes the <strong>Master</strong>.</li>
<li class="">The others become <strong>Workers</strong> (standby).</li>
<li class="">If the Master process dies, its ephemeral node in ZooKeeper disappears. The Worker nodes detect this event immediately and trigger a new election. One of them promotes itself to Master, ensuring zero downtime for the monitoring subsystem.</li>
</ul>
</li>
</ul>
<p><strong>System State Diagram (So Far):</strong></p>
<!-- -->
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-understanding-scalability-of-the-load-balancer-itself">4) Understanding Scalability of the Load Balancer Itself<a href="#4-understanding-scalability-of-the-load-balancer-itself" class="hash-link" aria-label="Direct link to 4) Understanding Scalability of the Load Balancer Itself" title="Direct link to 4) Understanding Scalability of the Load Balancer Itself" translate="no">​</a></h2>
<p>We have scaled the backends, but what happens when the Load Balancer <em>itself</em> is overwhelmed?</p>
<p>A single LB instance has limits—CPU, Memory, and Network Bandwidth (throughput). To detect this, we inject metrics (active connections, request latency, CPU usage) into a Time-Series Database (like Prometheus or InfluxDB). When thresholds are breached, our Auto-Scaling Group triggers the provision of a new Load Balancer instance.</p>
<p><strong>The Discovery Problem:</strong>
If we add a new Load Balancer (IP: <code>10.0.0.50</code>) to help the existing one (IP: <code>10.0.0.10</code>), how do clients know? Clients typically have the domain <code>api.myblog.com</code> cached to point to <code>10.0.0.10</code>. We cannot put another Load Balancer in front of our Load Balancers, or we just move the bottleneck one layer up (turtles all the way down).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="routing-requests-amongst-different-lb-servers-via-coredns">Routing Requests amongst different LB servers via CoreDNS<a href="#routing-requests-amongst-different-lb-servers-via-coredns" class="hash-link" aria-label="Direct link to Routing Requests amongst different LB servers via CoreDNS" title="Direct link to Routing Requests amongst different LB servers via CoreDNS" translate="no">​</a></h3>
<p>We solve this using <strong>DNS Load Balancing</strong> with <strong>CoreDNS</strong>.</p>
<p>CoreDNS is a flexible, extensible DNS server that can serve as the entry point for our traffic. Instead of a static mapping, CoreDNS can dynamically return different IP addresses for the same domain name.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-round-robin--weighted-load-balancing">1. Round Robin &amp; Weighted Load Balancing<a href="#1-round-robin--weighted-load-balancing" class="hash-link" aria-label="Direct link to 1. Round Robin &amp; Weighted Load Balancing" title="Direct link to 1. Round Robin &amp; Weighted Load Balancing" translate="no">​</a></h4>
<p>CoreDNS can be configured to return multiple A records (IP addresses) for a single domain. Modern clients (browsers, mobile apps) will try these IPs. We can update these records dynamically as we scale our LB fleet.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-geolocation--latency-routing">2. Geolocation &amp; Latency Routing<a href="#2-geolocation--latency-routing" class="hash-link" aria-label="Direct link to 2. Geolocation &amp; Latency Routing" title="Direct link to 2. Geolocation &amp; Latency Routing" translate="no">​</a></h4>
<p>CoreDNS can utilize plugins (like the <code>geoip</code> plugin) to inspect the source IP of the incoming DNS query.</p>
<ul>
<li class=""><strong>User from India</strong> -&gt; CoreDNS resolves <code>blog.com</code> to the VIP (Virtual IP) of the LB cluster in Mumbai.</li>
<li class=""><strong>User from US</strong> -&gt; CoreDNS resolves <code>blog.com</code> to the VIP of the LB cluster in Virginia.</li>
</ul>
<p><strong>Technical Implementation:</strong>
CoreDNS often uses an <code>etcd</code> backend to store records, allowing for real-time updates without restarting the DNS server. Here is how a <strong>JSON</strong> record for an LB service might look inside the store that CoreDNS reads:</p>
<p><strong>The CoreDNS Configuration (Corefile):</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">. {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    etcd myblog.com {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        path /skydns</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        endpoint http://etcd-cluster:2379</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loadbalance round_robin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cache 30</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>The Data (stored in etcd as JSON):</strong>
This is the &quot;Service Discovery&quot; record. The key path represents the domain, and the value is the target LB.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">/* Key: /skydns/com/myblog/api/lb1 */</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;host&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;10.0.0.10&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;port&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">80</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;priority&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;weight&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;text&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Location: US-East&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">/* Key: /skydns/com/myblog/api/lb2 */</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;host&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;10.0.0.50&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;port&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">80</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;priority&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;weight&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;text&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Location: US-East&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<p><em>Note: By adjusting the <code>weight</code> or removing the entry, we control traffic flow to the LBs instantly.</em></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-making-the-discovery-layer-highly-available">5) Making the Discovery Layer Highly Available<a href="#5-making-the-discovery-layer-highly-available" class="hash-link" aria-label="Direct link to 5) Making the Discovery Layer Highly Available" title="Direct link to 5) Making the Discovery Layer Highly Available" translate="no">​</a></h2>
<p>We have introduced CoreDNS to handle the discovery of our Load Balancers. But we have introduced a new problem: <strong>What if the CoreDNS server itself goes down?</strong></p>
<p>If our DNS layer fails, new clients cannot resolve the domain name to an IP address. Even if our Load Balancers and Backend Servers are healthy, the door to our system is effectively locked.</p>
<p>To solve this, we cannot simply spin up two CoreDNS servers with different IP addresses and hope for the best. Clients typically configure a specific IP (or a limited list) for their DNS resolver. We need a way to have multiple DNS servers &quot;share&quot; a single, highly available IP address.</p>
<p><strong>Enter Keepalived and the Virtual IP (VIP).</strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-concept-virtual-ip-vip">The Concept: Virtual IP (VIP)<a href="#the-concept-virtual-ip-vip" class="hash-link" aria-label="Direct link to The Concept: Virtual IP (VIP)" title="Direct link to The Concept: Virtual IP (VIP)" translate="no">​</a></h3>
<p>In standard networking, two machines cannot share the same IP address on the same network segment. If they do, it causes an IP conflict, and switches/routers get confused about where to send packets.</p>
<p>A <strong>Virtual IP (VIP)</strong> is a &quot;floating&quot; IP address that is not permanently bound to a specific physical machine&#x27;s network interface. Instead, it is a resource that can be dynamically claimed by a machine.</p>
<ol>
<li class="">We assign a VIP (e.g., <code>192.168.1.100</code>) to our DNS cluster.</li>
<li class="">Clients are configured to send DNS queries to <code>192.168.1.100</code>.</li>
<li class="">Only the <strong>Master</strong> node currently &quot;holds&quot; this IP.</li>
<li class="">If the Master dies, a <strong>Backup</strong> node detects the failure and immediately &quot;claims&quot; the IP, handling traffic seamlessly.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-solution-keepalived">The Solution: Keepalived<a href="#the-solution-keepalived" class="hash-link" aria-label="Direct link to The Solution: Keepalived" title="Direct link to The Solution: Keepalived" translate="no">​</a></h3>
<p>We use <strong>Keepalived</strong>, a routing software that implements the <strong>VRRP (Virtual Router Redundancy Protocol)</strong>.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-vrrp-works">How VRRP Works<a href="#how-vrrp-works" class="hash-link" aria-label="Direct link to How VRRP Works" title="Direct link to How VRRP Works" translate="no">​</a></h4>
<p>VRRP is designed to eliminate single points of failure.</p>
<ul>
<li class="">The nodes in the cluster communicate using <strong>Multicast</strong> packets.</li>
<li class="">The <strong>Master</strong> node periodically sends &quot;advertisements&quot; (heartbeats) to the multicast group.</li>
<li class="">The <strong>Backup</strong> nodes listen for these advertisements.</li>
<li class="">If the Backup nodes stop receiving advertisements (meaning the Master is dead or network partitioned), the Backup with the highest priority promotes itself to Master and claims the VIP.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-configuration-keepalivedconf">The Configuration: <code>keepalived.conf</code><a href="#the-configuration-keepalivedconf" class="hash-link" aria-label="Direct link to the-configuration-keepalivedconf" title="Direct link to the-configuration-keepalivedconf" translate="no">​</a></h4>
<p>Let&#x27;s look at the implementation. We install Keepalived on both CoreDNS servers.</p>
<p><strong>Master Node Configuration (<code>/etc/keepalived/keepalived.conf</code>):</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">vrrp_instance VI_1 {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    state MASTER           # 1. Initial State</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interface eth0         # 2. Network Interface to bind to</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    virtual_router_id 51   # 3. Unique ID for this cluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    priority 100           # 4. Election Priority (Higher wins)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    advert_int 1           # 5. Advertisement Interval (1 second)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    authentication {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auth_type PASS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auth_pass my_secret_password</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    virtual_ipaddress {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        192.168.1.100/24   # 6. The Virtual IP (VIP)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p><strong>Backup Node Configuration:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">vrrp_instance VI_1 {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    state BACKUP           # Starts as backup</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interface eth0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    virtual_router_id 51   # Must match the Master</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    priority 90            # Lower priority than Master</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    advert_int 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    authentication {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auth_type PASS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auth_pass my_secret_password</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    virtual_ipaddress {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        192.168.1.100/24   # Must match the Master</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>We have now eliminated the final Single Point of Failure in our control path.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="final-architecture-the-complete-picture">Final Architecture: The Complete Picture<a href="#final-architecture-the-complete-picture" class="hash-link" aria-label="Direct link to Final Architecture: The Complete Picture" title="Direct link to Final Architecture: The Complete Picture" translate="no">​</a></h2>
<p>We have now evolved a robust, scalable, and self-healing L7 Load Balancer system.</p>
<ol>
<li class=""><strong>Clients</strong> query <strong>CoreDNS</strong> to find an available Load Balancer.</li>
<li class=""><strong>CoreDNS</strong> returns the IP of a healthy LB (based on Geo/Load).</li>
<li class=""><strong>L7 Load Balancers</strong> receive traffic. They read their routing rules and backend lists from <strong>ZooKeeper</strong> (cached in memory).</li>
<li class=""><strong>Backend Servers</strong> process the requests.</li>
<li class=""><strong>Orchestrator Cluster</strong> (Master/Worker) continuously probes Backends and updates <strong>ZooKeeper</strong> if health status changes.</li>
<li class=""><strong>ZooKeeper</strong> pushes config updates to LBs in real-time.</li>
</ol>
</div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/docs/blog/tags/system-design">system-design</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/docs/blog/tags/load-balancer">load-balancer</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/docs/blog/tags/distributed-systems">distributed-systems</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/docs/blog/tags/aws">aws</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/docs/blog/tags/zookeeper">zookeeper</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"></div></footer></div>
</body>
</html>